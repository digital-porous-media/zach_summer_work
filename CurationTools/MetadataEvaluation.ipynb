{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57de24a-a4f1-49ea-a09d-3c8f63ff7fed",
   "metadata": {},
   "source": [
    "### Creates a spreadsheet with evaluations of the metadata based on whether it is in the required field. It is not up to date for the new data model which includes expansions to sample information and related datasets and software systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff29241-2b29-4ac9-b0e4-5b41b28fc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required libraries\n",
    "import openpyxl\n",
    "from openpyxl import Workbook, styles\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import CellIsRule, ColorScaleRule, FormulaRule, IconSetRule\n",
    "from openpyxl.utils import get_column_letter\n",
    "import json\n",
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3362964-1ea8-41f2-b51a-e20a905338a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required fields as dictated by the data model\n",
    "global required_fields\n",
    "required_fields = ['dataset: title', 'dataset: description', 'related publication: publicationTitle', \n",
    "                   'related publication: publicationAuthor', 'related publication: publicationPublisher', \n",
    "                   'related publication: publicationDateOfPublication', 'sample: name', 'sample: description', \n",
    "                   'sample: porousMediaType', 'sample: source', 'digital dataset: name', \n",
    "                   'digital dataset: isSegmented', 'digital dataset: description','analysis dataset: isSegmented', \n",
    "                   'analysis dataset: name', 'analysis dataset: description', 'analysis dataset: datasetType']\n",
    "\n",
    "global requirement_weight\n",
    "requirement_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f0ddb-b75e-4f14-bd6b-3d9e7889967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if a provided field is blank or not. If it has certain text that might be a researcher trying to avoid a required field, that is logged to the trips variable\n",
    "def exists(field,name,index):\n",
    "    global trips\n",
    "    if field == None:\n",
    "        return False\n",
    "    elif field == \"-\" or field == \"\" or field == \"N/A\" or field == \"n/a\":\n",
    "        trip = {\"loc\":filename,\"field\":name,\"nodeNum\":index,\"input\":field}\n",
    "        trips.append(trip)\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66027736-4ba3-4063-8650-64f07b5b3ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks all the fields for a dataset\n",
    "def check_dataset():\n",
    "    counter = {}\n",
    "    fields = [\"title\",\"description\",\"authors\",\"publicationDate\",\"doi\",\"license\"]\n",
    "    for field in fields:\n",
    "        if exists(metadata.get('nodes')[0].get(\"value\").get(field),field,0):\n",
    "            counter[field] = counter.get(field,0)+1\n",
    "        else:\n",
    "            counter[field] = counter.get(field,0)\n",
    "            \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92505726-4348-48b2-8e81-fe3ff2e2f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks all the fields for a related publication\n",
    "def check_related_pubs():\n",
    "    pubs = 0\n",
    "    counter = {}\n",
    "    fields = [\"publicationTitle\",\"publicationAuthor\",\"publicationPublisher\",\"publicationDateOfPublication\",\"publicationLink\",\n",
    "             \"publicationDescription\"]\n",
    "    for field in fields:\n",
    "        counter[field]=0\n",
    "    for pub in metadata.get('nodes')[0].get('value').get('relatedPublications'):\n",
    "        pubs += 1\n",
    "        for field in fields:\n",
    "            if exists(pub.get(field),field,metadata.get('nodes')[0].get('value').get('relatedPublications').index(pub)):\n",
    "                counter[field] = counter.get(field,0)+1\n",
    "            else:\n",
    "                counter[field] = counter.get(field,0)\n",
    "    for key in counter.keys():\n",
    "        try:\n",
    "            counter[key] = counter[key]/pubs\n",
    "        except ZeroDivisionError:\n",
    "            counter[key] = \"N/A\"\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3417a1e-9985-4888-86ed-1f7f3a354668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks all the fields for a sample\n",
    "def check_sample():\n",
    "    count = 0\n",
    "    counter = {}\n",
    "    fields = [\"name\",\"description\",\"porousMediaType\",\"source\",\"geographicalLocation\",'grainSizeAvg', 'grainSizeMax', \n",
    "              'grainSizeMin','porosity']\n",
    "    for field in fields:\n",
    "        counter[field]=0\n",
    "    for node in metadata.get(\"nodes\"):\n",
    "        if node.get(\"value\").get(\"dataType\") == \"sample\":\n",
    "            count+=1\n",
    "            for field in fields:\n",
    "                if exists(node.get(\"value\").get(field),field,metadata.get('nodes').index(node)):\n",
    "                    counter[field] = counter.get(field,0)+1\n",
    "                else:\n",
    "                    counter[field] = counter.get(field,0)\n",
    "    for key in counter.keys():\n",
    "        try:\n",
    "            counter[key] = counter[key]/count\n",
    "        except ZeroDivisionError:\n",
    "            counter[key] = \"N/A\"\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fdd21-b427-4d2f-8f66-471864cd647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks all the fields for a digital dataset\n",
    "def check_digital_dataset():\n",
    "    count = 0\n",
    "    counter = {}\n",
    "    fields = [\"name\",\"isSegmented\",\"description\",\"voxelX\",\"voxelY\",\"voxelZ\",\"voxelUnits\"]\n",
    "    for field in fields:\n",
    "        counter[field]=0\n",
    "    for node in metadata.get(\"nodes\"):\n",
    "        if node.get(\"value\").get(\"dataType\") == \"digital_dataset\":\n",
    "            count+=1\n",
    "            for field in fields:\n",
    "                if exists(node.get(\"value\").get(field),field,metadata.get('nodes').index(node)):\n",
    "                    counter[field] = counter.get(field,0)+1\n",
    "                else:\n",
    "                    counter[field] = counter.get(field,0)\n",
    "    for key in counter.keys():\n",
    "        try:\n",
    "            counter[key] = counter[key]/count\n",
    "        except ZeroDivisionError:\n",
    "            counter[key] = \"N/A\"\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5af95-10b7-43a2-8f99-7508fd8a74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks all the fields for an analysis dataset\n",
    "def check_analysis_dataset():\n",
    "    count = 0\n",
    "    counter = {}\n",
    "    fields = [\"isSegmented\",\"name\",\"description\",\"datasetType\"]\n",
    "    for field in fields:\n",
    "        counter[field]=0\n",
    "    for node in metadata.get(\"nodes\"):\n",
    "        if node.get(\"value\").get(\"dataType\") == \"analysis_data\":\n",
    "            count+=1\n",
    "            for field in fields:\n",
    "                if exists(node.get(\"value\").get(field),field,metadata.get('nodes').index(node)):\n",
    "                    counter[field] = counter.get(field,0)+1\n",
    "                else:\n",
    "                    counter[field] = counter.get(field,0)\n",
    "    for key in counter.keys():\n",
    "        try:\n",
    "            counter[key] = counter[key]/count\n",
    "        except ZeroDivisionError:\n",
    "            counter[key] = \"N/A\"\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27242cd-ca95-45fa-86bf-519f35bedc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks through the fields of an entire dataset\n",
    "def check_all():\n",
    "    global averages\n",
    "    dataset = check_dataset()\n",
    "    sample = check_sample()\n",
    "    related_pubs = check_related_pubs()\n",
    "    digital_dataset = check_digital_dataset()\n",
    "    analysis_dataset = check_analysis_dataset()\n",
    "    data = [(dataset,\"dataset:\"),(related_pubs,\"related publication:\"),(sample,\"sample:\"),(digital_dataset,\"digital dataset:\"),\n",
    "            (analysis_dataset,\"analysis dataset:\")]\n",
    "    weights = []\n",
    "    keys = []\n",
    "    for element in data:\n",
    "        weights.extend(list(element[0].values()))\n",
    "        keys.extend([element[1] +' '+item for item in list(element[0].keys())])\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for key, weight in zip(keys, weights):\n",
    "        if weight != 'N/A':\n",
    "            if key in required_fields:\n",
    "                total += requirement_weight*weight\n",
    "                count += requirement_weight\n",
    "            else:\n",
    "                total += weight\n",
    "                count += 1\n",
    "    avg = total/count\n",
    "    keys.append('totalScore')\n",
    "    weights.append(avg)\n",
    "    averages.append(avg)\n",
    "    return keys, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c8e05-e1b5-486d-901c-c7432393d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an Excel sheet with all the information on all datasets. It is also color coded with red as 0% of a field full and green as 100% of the field full\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "# Weight given to required fields in the final average. 1 is equal weight, 0 is no weight, anything higher than 1 is that amount of weight greater.\n",
    "requirement_weight = 2\n",
    "\n",
    "global averages\n",
    "averages = []\n",
    "\n",
    "# Please put in the name of the filepath to all metadatafiles\n",
    "filepath = \"file/path/to/all/MetadataFiles\"\n",
    "directory = os.fsencode(filepath)\n",
    "ls = check_all()\n",
    "ws.append([\"project number\"]+ls[0])\n",
    "\n",
    "global trips\n",
    "trips = []\n",
    "\n",
    "global filename\n",
    "for file in os.listdir(directory):\n",
    "    if os.fsdecode(file) != \".DS_Store\":\n",
    "        filename = os.fsdecode(file)\n",
    "        full_filename = filepath+filename\n",
    "        with open(full_filename, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "        ls = check_all()\n",
    "        ws.append([int(re.findall(r'\\d{1,3}',filename)[0])]+ls[1])\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "color_rule = ColorScaleRule(start_type='num', start_value=0, start_color='FF9C9C',\n",
    "                            mid_type='num', mid_value=.5, mid_color='FFFFFF',\n",
    "                            end_type='num', end_value=1, end_color='6AA84F')\n",
    "\n",
    "col = get_column_letter(len(ls[0]))\n",
    "row = str(len(os.listdir(directory)))\n",
    "scope = 'B2:'+col+row\n",
    "\n",
    "ws.conditional_formatting.add(\n",
    "    scope,\n",
    "    color_rule\n",
    ")\n",
    "\n",
    "color_rule = ColorScaleRule(start_type='num', start_value=min(averages), start_color='FFFFFF',\n",
    "                            # mid_type='num', mid_value=.5, mid_color='FFFFFF',\n",
    "                            end_type='num', end_value=1, end_color='6AA84F')\n",
    "\n",
    "col = get_column_letter(len(ls[0])+1)\n",
    "scope = col+'2:'+col+row\n",
    "\n",
    "ws.conditional_formatting.add(\n",
    "    scope,\n",
    "    color_rule\n",
    ")\n",
    "\n",
    "wb.save(\"MetadataEvaluation.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
