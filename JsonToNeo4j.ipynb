{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82183485-9da6-4499-a1a0-4965fe93b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import regex as re\n",
    "import openai\n",
    "import credentials\n",
    "\n",
    "# Initalized and ensures the validity of Neo4j credentials. URI examples: \"neo4j://localhost\", \"neo4j+s://xxx.databases.neo4j.io\"\n",
    "URI = credentials.NEO4J_URI\n",
    "AUTH = credentials.NEO4J_AUTH\n",
    "\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a84a-2a5a-432f-8263-d6847fc8e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All root nodes share an id of \"NODE_ROOT\" and this can cause issues. This appends the project id so as to clarify which root node is used\n",
    "def specify_root():\n",
    "    global new_root_name\n",
    "    new_root_name = \"NODE_ROOT+\"+metadata.get(\"nodes\")[root_key].get(\"value\").get(\"projectId\")\n",
    "    for link in metadata.get(\"links\"):\n",
    "        if link.get(\"source\")==\"NODE_ROOT\":\n",
    "            link[\"source\"]=new_root_name\n",
    "    metadata.get(\"nodes\")[root_key][\"id\"]=new_root_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ac49d-9d5c-4fa1-b6a3-5e0c2e4db8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There does not seem to be a case so far where the root node is not the one at index 0 of the list of nodes, this function handels the chance that changes though.\n",
    "def find_root():\n",
    "    found = False\n",
    "    i = 0\n",
    "    for node in metadata.get(\"nodes\"):\n",
    "        if node.get(\"id\") == \"NODE_ROOT\":\n",
    "            return i\n",
    "    raise Exception(\"Root node could not be found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5325e0-ee35-4e7c-97b3-7f703bc5523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the dataset number (anywhere between 1-999)\n",
    "def get_dataset_number():\n",
    "    projectID = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"projectId\")\n",
    "    num = re.findall(r'\\d{1,3}',projectID)\n",
    "    return int(num[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3c80d-2b06-4bc6-8426-6af9d5d73e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials for both the LLM and embedding models contained in credentials.py\n",
    "CHATBOT_API_KEY = credentials.CHATBOT_API_KEY\n",
    "CHATBOT_BASE_URL = credentials.CHATBOT_URL\n",
    "CHATBOT_MODEL = credentials.CHATBOT_MODEL\n",
    "\n",
    "EMBEDDING_API_KEY = credentials.EMBEDDING_API_KEY\n",
    "EMBEDDING_URL = credentials.EMBEDDING_URL\n",
    "EMBEDDING_MODEL = credentials.EMBEDDING_MODEL\n",
    "\n",
    "# Temperature and Top_P parameters decided on in the credentials.py file\n",
    "TEMP = credentials.TEMP\n",
    "TOP_P = credentials.TOP_P\n",
    "\n",
    "# Create clients with both the embedding model and llm model\n",
    "keyword_client = openai.OpenAI(\n",
    "    api_key=CHATBOT_API_KEY,\n",
    "    base_url=CHATBOT_BASE_URL,\n",
    ")\n",
    "\n",
    "embedding_client = openai.OpenAI(\n",
    "    base_url=EMBEDDING_URL,\n",
    "    api_key=EMBEDDING_API_KEY,\n",
    ")\n",
    "\n",
    "# Takes in a data description and uses the LLM to return a list of keywords\n",
    "def keywords(text):\n",
    "    response = keyword_client.chat.completions.create(\n",
    "        model=CHATBOT_MODEL,\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant who must find key words in a given data description. Return only a comma seperated list of those key words. Return the list only once, do not try to reformat it\"},{\"role\":\"user\",\"content\":text}],\n",
    "        temperature =  TEMP,\n",
    "        top_p = TOP_P\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Takes in a piece of text and embeds it as a vector\n",
    "def embed(text):\n",
    "    response = embedding_client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=[text]\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Returns a pair of keywords and their corresponding embedding\n",
    "def return_keywords(description):\n",
    "    desc_keywords = keywords(description)\n",
    "    embedded_keywords = embed(desc_keywords)\n",
    "    return (desc_keywords,embedded_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48ac91-3030-431b-a1f1-f75a355ff38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because there may be many authors, the first and last names are concatenated and then all authors are joined in one string which passes to dataset\n",
    "def author_names():\n",
    "    names = []\n",
    "    authors = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"authors\")\n",
    "    for person in authors:\n",
    "        name = person.get('first_name') + ' ' + person.get('last_name')\n",
    "        names.append(name)\n",
    "    return ', '.join(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab0b06-b33e-4f96-8d2f-93bc08d0da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataset node which is the parent of all other nodes\n",
    "def create_dataset():\n",
    "    title = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"title\")\n",
    "    description = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"description\")\n",
    "    doi = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"doi\")\n",
    "    identifier = metadata.get(\"nodes\")[root_key].get(\"id\")\n",
    "    authors = author_names()\n",
    "    license = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"license\")\n",
    "    pub_date = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"publicationDate\")\n",
    "    # identified_keywords = return_keywords(description)\n",
    "    # llm_keywords = identified_keywords[0]\n",
    "    # embedding = identified_keywords[1]\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (p:Dataset {title: $title})\n",
    "            SET p.description = $description\n",
    "            SET p.doi = $doi\n",
    "            SET p.identifier = $identifier\n",
    "            SET p.authors = $authors\n",
    "            SET p.license = $license\n",
    "            SET p.publicationDate = $pub_date\n",
    "            SET p.datasetNumber = $dataset_number\n",
    "            //SET p.llmKeywords = $llm_keywords\n",
    "            //SET p.descriptionEmbedding = $embedding\n",
    "            \"\"\",\n",
    "            title=title, description=description, doi=doi, identifier=identifier,\n",
    "            authors=authors,license=license, pub_date=pub_date,dataset_number=dataset_number,#embedding=embedding,\n",
    "            #llm_keywords=llm_keywords,\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b273ae-5ae1-42c2-9932-b894101b9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a related publication node based on the index provided (there may be many related publications in a list)\n",
    "def create_related_publication(pub_key):\n",
    "    pub_title = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedPublications\")[pub_key].get('publicationTitle')\n",
    "    pub_author = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedPublications\")[pub_key].get('publicationAuthor')\n",
    "    pub_abstract = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedPublications\")[pub_key].get('publicationDescription')\n",
    "    pub_link = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedPublications\")[pub_key].get('publicationLink')\n",
    "    pub_publicationDate = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedPublications\")[pub_key].get('publicationDateOfPublication')\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (rp:RelatedPublication {title: $pub_title})\n",
    "            SET rp.authors = $pub_author\n",
    "            SET rp.abstract = $pub_abstract\n",
    "            SET rp.link = $pub_link\n",
    "            SET rp.publicationDate = $pub_publicationDate\n",
    "            SET rp.datasetNumber = $dataset_number\n",
    "            WITH rp\n",
    "            MATCH (p:Dataset{identifier:$project_id})\n",
    "            CREATE (p) <-[:PART_OF]- (rp)\n",
    "            \"\"\",\n",
    "            pub_title=pub_title, pub_author=pub_author, pub_abstract=pub_abstract,\n",
    "            pub_link=pub_link,pub_publicationDate=pub_publicationDate,project_id=new_root_name,dataset_number=dataset_number,\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb84d2-2569-4c32-9277-5e119b693ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a node for a related software. !!!This function was created before this field was fully availabe. It should be tested that this works correctly\n",
    "def create_related_software(software_key):\n",
    "    software_title = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedSoftware\")[software_key].get('softwareTitle')\n",
    "    software_description = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedSoftware\")[software_key].get('softwareDescription')\n",
    "    software_link = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedSoftware\")[software_key].get('softwareLink')\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (rs:RelatedSoftware {title: $software_title})\n",
    "            SET rs.description = $software_description\n",
    "            SET rs.link = $software_link\n",
    "            SET rs.datasetNumber = $dataset_number\n",
    "            WITH rs\n",
    "            MATCH (p:Dataset{identifier:$project_id})\n",
    "            CREATE (p) <-[:PART_OF]- (rs)\n",
    "            \"\"\",\n",
    "            software_title=software_title, software_description=software_description, software_link=software_link,\n",
    "            project_id=new_root_name,dataset_number=dataset_number,\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92228942-48e6-4fb3-b32a-4194267e2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a node for a related dataset. !!!This function was created before this field was fully availabe. It should be tested that this works correctly\n",
    "def create_related_dataset(dataset_key):\n",
    "    dataset_title = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedDatasets\")[dataset_key].get('datasetTitle')\n",
    "    dataset_description = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedDatasets\")[dataset_key].get('datasetDescription')\n",
    "    dataset_link = metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedDatasets\")[dataset_key].get('datasetLink')\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (rd:RelatedDataset {title: $dataset_title})\n",
    "            SET rd.description = $dataset_description\n",
    "            SET rd.link = $dataset_link\n",
    "            SET rd.datasetNumber = $dataset_number\n",
    "            WITH rd\n",
    "            MATCH (p:Dataset{identifier:$project_id})\n",
    "            CREATE (p) <-[:PART_OF]- (rd)\n",
    "            \"\"\",\n",
    "            dataset_title=dataset_title, dataset_description=dataset_description, dataset_link=dataset_link,\n",
    "            project_id=new_root_name,dataset_number=dataset_number,\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33610d4a-1aed-4ae0-850a-7cc8a300c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a sample node from the index provided.\n",
    "def create_sample(key):\n",
    "    sample_identifier = metadata.get(\"nodes\")[key].get(\"id\")\n",
    "    sample_location = metadata.get(\"nodes\")[key].get(\"value\").get(\"geographicalLocation\")\n",
    "    sample_media_type = metadata.get(\"nodes\")[key].get(\"value\").get(\"porousMediaType\")\n",
    "    sample_porosity = metadata.get(\"nodes\")[key].get(\"value\").get(\"porosity\")\n",
    "    sample_name = metadata.get(\"nodes\")[key].get(\"value\").get(\"name\")\n",
    "    sample_source = metadata.get(\"nodes\")[key].get(\"value\").get(\"source\")\n",
    "    sample_description = metadata.get(\"nodes\")[key].get(\"value\").get(\"description\")\n",
    "    sample_geographic_origin = metadata.get(\"nodes\")[key].get(\"value\").get(\"geographicOrigin\")\n",
    "    sample_grain_size_avg = metadata.get(\"nodes\")[key].get(\"value\").get(\"grainSizeAvg\")\n",
    "    sample_grain_size_min = metadata.get(\"nodes\")[key].get(\"value\").get(\"grainSizeMin\")\n",
    "    sample_grain_size_max = metadata.get(\"nodes\")[key].get(\"value\").get(\"grainSizeMax\")\n",
    "    sample_grain_size_units = metadata.get(\"nodes\")[key].get(\"value\").get(\"grainSizeUnits\")\n",
    "    sample_collection_method = metadata.get(\"nodes\")[key].get(\"value\").get(\"collectionMethod\")\n",
    "    sample_onshore_offshore = metadata.get(\"nodes\")[key].get(\"value\").get(\"onshoreOffshore\")\n",
    "    sample_depth = metadata.get(\"nodes\")[key].get(\"value\").get(\"depth\")\n",
    "    sample_water_depth = metadata.get(\"nodes\")[key].get(\"value\").get(\"waterDepth\")\n",
    "    sample_procedure = metadata.get(\"nodes\")[key].get(\"value\").get(\"procedure\")\n",
    "    sample_equipment = metadata.get(\"nodes\")[key].get(\"value\").get(\"equipment\")\n",
    "    sample_algorithm_description = metadata.get(\"nodes\")[key].get(\"value\").get(\"algorithmDescription\")\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (s:Sample{title:$sample_name})\n",
    "            SET s.identifier = $sample_identifier\n",
    "            SET s.location = $sample_location\n",
    "            SET s.porousMediaType = $sample_media_type\n",
    "            SET s.porosity = $sample_porosity\n",
    "            SET s.source = $sample_source\n",
    "            SET s.description = $sample_description\n",
    "            SET s.geographicOrigin = $sample_geographic_origin\n",
    "            SET s.grainSizeAvg = $sample_grain_size_avg\n",
    "            SET s.grainSizeMin = $sample_grain_size_min\n",
    "            SET s.grainSizeMax = $sample_grain_size_max\n",
    "            SET s.grainSizeUnits = $sample_grain_size_units\n",
    "            SET s.collectionMethod = $sample_collection_method\n",
    "            SET s.onshoreOffshore = $sample_onshore_offshore\n",
    "            SET s.depth = $sample_depth\n",
    "            SET s.waterDepth = $sample_water_depth\n",
    "            SET s.procedure = $sample_procedure\n",
    "            SET s.equipment = $sample_equipment\n",
    "            SET s.algorithmDescription = $sample_algorithm_description\n",
    "            SET s.datasetNumber = $dataset_number\n",
    "            \"\"\",\n",
    "            sample_identifier=sample_identifier,sample_location=sample_location,sample_media_type=sample_media_type,\n",
    "            sample_porosity=sample_porosity,sample_name=sample_name,sample_source=sample_source,\n",
    "            sample_description=sample_description, sample_geographic_origin=sample_geographic_origin,\n",
    "            sample_grain_size_avg=sample_grain_size_avg,sample_grain_size_min=sample_grain_size_min,\n",
    "            sample_grain_size_max=sample_grain_size_max,sample_grain_size_units=sample_grain_size_units,\n",
    "            sample_collection_method=sample_collection_method,sample_onshore_offshore=sample_onshore_offshore,\n",
    "            sample_depth=sample_depth,sample_water_depth=sample_water_depth,sample_procedure=sample_procedure,\n",
    "            sample_equipment=sample_equipment,sample_algorithm_description=sample_algorithm_description,\n",
    "            dataset_number=dataset_number,\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8efdc1-6177-4778-a259-9b69ad937fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all the information provided on voxel dimensions into one string\n",
    "def voxel_dim(key):\n",
    "    x = metadata.get(\"nodes\")[key].get(\"value\").get(\"voxelX\")\n",
    "    y = metadata.get(\"nodes\")[key].get(\"value\").get(\"voxelY\")\n",
    "    z = metadata.get(\"nodes\")[key].get(\"value\").get(\"voxelZ\")\n",
    "    dim = metadata.get(\"nodes\")[key].get(\"value\").get(\"voxelUnits\")\n",
    "    try:\n",
    "        string = \"X, Y, Z units (in \"+dim+\"s): \"+str(x)+\", \"+str(y)+\", \"+str(z)\n",
    "    except:\n",
    "        if x == None and y == None and z == None and dim == None:\n",
    "            return None\n",
    "        string = \"X, Y, Z units: \"+str(x)+\", \"+str(y)+\", \"+str(z)+\". Unit type not provided\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d86f64-e2c4-43a8-8dd5-50dfe30c6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the file types in that node\n",
    "def get_file_types(node):\n",
    "    node_files = set()\n",
    "    for file in node.get('value').get('fileObjs'):\n",
    "        try:\n",
    "            full_type = re.findall(r'(?:\\.[A-z]+\\d?)+$',file.get('path'))[0]\n",
    "            remove_front_dot = re.sub(r'^\\.','',full_type)\n",
    "            cleaned = re.sub(r'\\.thumb\\.jpg','',remove_front_dot)\n",
    "            cleaned = re.sub(r'npy_[A-z]{7}\\.','',cleaned)\n",
    "            cleaned = re.sub(r'\\.histogram\\.(?:(?:csv)|(?:jpg))','',cleaned)\n",
    "            node_files.add(cleaned.lower())\n",
    "            return list(node_files)\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd8f19-99de-4e4d-8d18-d41cc6cc37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a node for a digital dataset based on a provided index.\n",
    "def create_digital_dataset(key):\n",
    "    dig_identifier = metadata.get(\"nodes\")[key].get(\"id\")\n",
    "    dig_name = metadata.get(\"nodes\")[key].get(\"label\")\n",
    "    dig_voxels = voxel_dim(key)\n",
    "    dig_description = metadata.get(\"nodes\")[key].get(\"value\").get(\"description\")\n",
    "    dig_segmented = metadata.get(\"nodes\")[key].get(\"value\").get(\"isSegmented\")\n",
    "    dig_imaging_center = metadata.get(\"nodes\")[key].get(\"value\").get(\"imagingCenter\")\n",
    "    dig_imaging_equipment_and_model = metadata.get(\"nodes\")[key].get(\"value\").get(\"imagingEquipmentAndModel\")\n",
    "    dig_image_format = metadata.get(\"nodes\")[key].get(\"value\").get(\"imageFormat\")\n",
    "    dig_image_dimensions = metadata.get(\"nodes\")[key].get(\"value\").get(\"imageDimensions\")\n",
    "    dig_image_byte_order = metadata.get(\"nodes\")[key].get(\"value\").get(\"imageByteOrder\")\n",
    "    dig_dimensionality = metadata.get(\"nodes\")[key].get(\"value\").get(\"dimensionality\")\n",
    "    dig_files = len(metadata.get(\"nodes\")[key].get(\"value\").get(\"fileObjs\"))\n",
    "    dig_file_types = get_file_types(metadata.get(\"nodes\")[key])\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (dd:DigitalDataset{title:$dig_name})\n",
    "            SET dd.identifier = $dig_identifier\n",
    "            SET dd.voxelDimensions = $dig_voxels\n",
    "            SET dd.description = $dig_description\n",
    "            SET dd.segmented = $dig_segmented\n",
    "            SET dd.imagingCenter = $dig_imaging_center\n",
    "            SET dd.imagingEquipmentAndModel = $dig_imaging_equipment_and_model\n",
    "            SET dd.imageFormat = $dig_image_format\n",
    "            SET dd.imageDimensions = $dig_image_dimensions\n",
    "            SET dd.imageByteOrder = $dig_image_byte_order\n",
    "            SET dd.dimensionality = $dig_dimensionality\n",
    "            SET dd.numberOfFiles = $dig_files\n",
    "            SET dd.datasetNumber = $dataset_number\n",
    "            SET dd.fileTypes = $dig_file_types\n",
    "            \"\"\",\n",
    "            dig_identifier=dig_identifier,dig_name=dig_name,dig_voxels=dig_voxels,\n",
    "            dig_description=dig_description,dig_segmented=dig_segmented,dig_imaging_center=dig_imaging_center,\n",
    "            dig_imaging_equipment_and_model=dig_imaging_equipment_and_model,dig_image_format=dig_image_format,\n",
    "            dig_image_dimensions=dig_image_dimensions,dig_image_byte_order=dig_image_byte_order,\n",
    "            dig_dimensionality=dig_dimensionality,dig_files=dig_files,dataset_number=dataset_number,\n",
    "            dig_file_types=dig_file_types,\n",
    "            database_=\"neo4j\",\n",
    "        )\n",
    "    make_part_of(dig_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c22ea7-755d-4c5f-8e8e-41ac97ac36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an analysis dataset node from the index provided\n",
    "def create_analysis_dataset(key):\n",
    "    analysis_identifier = metadata.get(\"nodes\")[key].get(\"id\")\n",
    "    analysis_name = metadata.get(\"nodes\")[key].get(\"label\")\n",
    "    analysis_segmented = metadata.get(\"nodes\")[key].get(\"value\").get(\"isSegmented\")\n",
    "    analysis_description = metadata.get(\"nodes\")[key].get(\"value\").get(\"description\")\n",
    "    analysis_type = metadata.get(\"nodes\")[key].get(\"value\").get(\"datasetType\")\n",
    "    analysis_digital_dataset = metadata.get(\"nodes\")[key].get(\"value\").get(\"digitalDataset\")\n",
    "    analysis_sample = metadata.get(\"nodes\")[key].get(\"value\").get(\"sample\")\n",
    "    analysis_files = len(metadata.get(\"nodes\")[key].get(\"value\").get(\"fileObjs\"))\n",
    "    analysis_file_types = get_file_types(metadata.get(\"nodes\")[key])\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            CREATE (ad:AnalysisDataset{title:$analysis_name})\n",
    "            SET ad.identifier = $analysis_identifier\n",
    "            SET ad.segmented = $analysis_segmented\n",
    "            SET ad.description = $analysis_description\n",
    "            SET ad.type = $analysis_type\n",
    "            SET ad.referencedDigitalDataset = $analysis_digital_dataset\n",
    "            SET ad.referencedSample = $analysis_sample\n",
    "            SET ad.datasetNumber = $dataset_number\n",
    "            SET ad.numberOfFiles = $analysis_files\n",
    "            SET ad.fileTypes = $analysis_file_types\n",
    "            \"\"\",\n",
    "            analysis_name=analysis_name, analysis_segmented=analysis_segmented, analysis_identifier=analysis_identifier,\n",
    "            analysis_description=analysis_description, analysis_type=analysis_type, analysis_files=analysis_files,\n",
    "            analysis_digital_dataset=analysis_digital_dataset,analysis_sample=analysis_sample,dataset_number=dataset_number,\n",
    "            analysis_file_types=analysis_file_types,\n",
    "            database_=\"neo4j\",\n",
    "        )\n",
    "    make_part_of(analysis_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e2562-7984-4549-a1c5-b7681c0e96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PartOf relationship between Digital and Analysis dataset nodes and the Dataset node are not present in the list of \"links.\" So instead this function creates the appropriate arrows for that pointing\n",
    "def make_part_of(node_id):\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            MATCH (n{identifier:$node_id})\n",
    "            MATCH (r:Dataset{identifier:$identifier})\n",
    "            MERGE (n) -[:PART_OF]-> (r)\n",
    "            \"\"\",\n",
    "            node_id=node_id,identifier=new_root_name,\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a5120-af40-42a5-bf2c-6e44e420095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a relationship between two nodes identified by the 'source' and 'target' parameters. Is a PartOf relationship if it is the sample pointing to the root and InputFor if is somewhere else\n",
    "def establish_connection(source,target):\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        if source == new_root_name:\n",
    "            driver.execute_query(\"\"\"\n",
    "                MATCH (s{identifier:$source})\n",
    "                MATCH (t{identifier:$target})\n",
    "                CREATE (s) <-[:PART_OF]- (t)\n",
    "            \"\"\",\n",
    "            source=source, target=target,\n",
    "            database_=\"neo4j\",\n",
    "            )\n",
    "        else:\n",
    "            driver.execute_query(\"\"\"\n",
    "                MATCH (s{identifier:$source})\n",
    "                MATCH (t{identifier:$target})\n",
    "                CREATE (s) <-[:INPUT_FOR]- (t)\n",
    "            \"\"\",\n",
    "            source=source, target=target,\n",
    "            database_=\"neo4j\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ab167-c6c9-4348-a88a-479fb06679f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a Neo4j graph for a single metadata file. That file is first opened and loaded as a json file. A related publication is created for each index in that list, same with related software and datasets. And finally the list of nodes is iterated through and depending on the data type, the appropriate node is created.\n",
    "def create_neo4j(filename):\n",
    "    with open(filename, 'r') as single_file:\n",
    "        global metadata    \n",
    "        metadata = json.load(single_file)\n",
    "    global root_key \n",
    "    root_key = find_root()\n",
    "    global dataset_number\n",
    "    dataset_number = get_dataset_number()\n",
    "    specify_root()\n",
    "    create_dataset()\n",
    "    for i in range(len(metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedPublications\"))):\n",
    "        create_related_publication(i)\n",
    "    for i in range(len(metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedSoftware\"))):\n",
    "        create_related_software(i)\n",
    "    for i in range(len(metadata.get(\"nodes\")[root_key].get(\"value\").get(\"relatedDatasets\"))):\n",
    "        create_related_dataset(i)\n",
    "    for i in range(len(metadata.get(\"nodes\"))):\n",
    "        if metadata.get(\"nodes\")[i].get(\"value\").get(\"dataType\")==\"sample\":\n",
    "            create_sample(i)\n",
    "        if metadata.get(\"nodes\")[i].get(\"value\").get(\"dataType\")==\"digital_dataset\":\n",
    "            create_digital_dataset(i)\n",
    "        if metadata.get(\"nodes\")[i].get(\"value\").get(\"dataType\")==\"analysis_data\":\n",
    "            create_analysis_dataset(i)\n",
    "    for link in metadata.get(\"links\"):\n",
    "        establish_connection(link.get(\"source\"),link.get(\"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4fca0-db6d-4e13-89e3-666a40c59540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_identifiers():\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            MATCH (n)\n",
    "            REMOVE n.identifier\n",
    "            \"\"\",\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a354e2-63a6-41c2-8b9b-7d3181f38963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all nodes in the Neo4j instance\n",
    "def clear():\n",
    "    with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "        driver.execute_query(\"\"\"\n",
    "            MATCH (n)\n",
    "            DETACH DELETE n\n",
    "            \"\"\",\n",
    "            database_=\"neo4j\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca383d-f5ee-4e5d-acd4-9b0b9545e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacks every file in the folder of metadata files and creates a Neo4j graph for each of them\n",
    "folder = '/Users/zacharynowacek/Desktop/Austin/DRP-Metadata'\n",
    "\n",
    "directory = os.fsencode(folder)\n",
    "\n",
    "clear()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if os.fsdecode(file) != \".DS_Store\":\n",
    "        filename = os.fsdecode(file)\n",
    "        filename = folder+'/'+filename\n",
    "        create_neo4j(filename)\n",
    "remove_identifiers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
